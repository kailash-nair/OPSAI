# =========================
# Server (Node/Express)
# =========================
PORT=5001
# Allow your Vite frontend to call the API
WEB_ORIGIN=http://localhost:5173

# Processing mode: "mock" (no Python) or "python" (runs main.py)
AGENT_MODE=python

# =========================
# Python Agent settings (only used when AGENT_MODE=python)
# =========================
# How to invoke Python on Windows: "python" or "py"
PYTHON_EXE=python

# Path to your Python agent entry file (relative to server/index.js)
AGENT_MAIN=../main.py

# Default attendees string passed to the agent (you can change per meeting if you want)
AGENT_ATTENDEES=Rahul; Meera; Akash

# =========================
# OpenAI + LLM config (used by main.py)
# =========================
# REQUIRED when AGENT_MODE=python and STT_BACKEND=openai (or for LLM summarization)
OPENAI_API_KEY=

# Optional: custom base URL if you use a proxy or Azure; otherwise leave blank
OPENAI_BASE_URL=https://api.openai.com/v1

# LLM used for register transform / summarization / translations
LLM_MODEL=gpt-4o-mini

# =========================
# Speech-to-Text backend selection (main.py)
# One of: openai | faster_whisper | hf_whisper_ml | hf_wav2vec2_ml
# =========================
STT_BACKEND=hf_wav2vec2_ml

# If using OpenAI Whisper API
WHISPER_MODEL=gpt-4o-transcribe

# If using Faster-Whisper (local)
FW_MODEL=large-v3
# Common Windows-friendly compute type (falls back automatically)
FW_COMPUTE_TYPE=int8_float16

# If using HF Whisper Malayalam fine-tune (local) + LLM translation
HF_WHISPER_ML_MODEL=vrclc/Whisper-medium-Malayalam
# Chunk size in seconds (reduce if you run out of VRAM/RAM)
WHISPER_CHUNK_SECONDS=30

# If using HF Wav2Vec2 Malayalam (local CTC) + LLM translation
HF_W2V2_ML_MODEL=gvs/wav2vec2-large-xlsr-malayalam
W2V2_CHUNK_SECONDS=30

# Malayalam XLM-R model for department cue tagging
HF_MLXLMR_MODEL=bytesizedllm/MalayalamXLM_Roberta
